{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f318ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import essentia\n",
    "import essentia.standard as es\n",
    "import librosa\n",
    "import librosa.display\n",
    "# IMPORTANT: since TCN is not available on pip version of madmom\n",
    "# you have to build the library from source\n",
    "import madmom\n",
    "import matplotlib.pyplot as plt\n",
    "import mirdata\n",
    "import mir_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import src.baseline as baseline\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path.cwd()\n",
    "\n",
    "experiments_path = base_path / \"results\" / \"baselines\"\n",
    "# output_path = base_path / \"experiments_results\" / \"beat_trackers_baseline\"\n",
    "candombe_path = base_path.parent.parent / \"datasets\" / \"candombe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216d5a6",
   "metadata": {},
   "source": [
    "Important dataset information:\n",
    "* Candombe:\n",
    "    * sampling rate: 44100 Hz\n",
    "    * precision: 16-bit\n",
    "    * total audios: 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d137ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan = mirdata.initialize('gtzan_genre', version='mini')\n",
    "# gtzan.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea638f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d0a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper dicts\n",
    "baselines = {\n",
    "    \"librosa\": baseline.librosa_beats,\n",
    "    \"madmom_rnn\": baseline.madmom_rnn_beats,\n",
    "    \"madmom_tcn\": baseline.madmom_tcn_beats,\n",
    "    \"essentia\": baseline.essentia_beats\n",
    "}\n",
    "\n",
    "times = {\n",
    "    \"librosa\": {},\n",
    "    \"madmom_rnn\": {},\n",
    "    \"madmom_tcn\": {},\n",
    "    \"essentia\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f6673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# candombe\n",
    "audiofiles = candombe_path.rglob(\"*.wav\")\n",
    "\n",
    "for audio in audiofiles:\n",
    "    x, _ = librosa.load(audio, mono=True, sr=SR)\n",
    "    \n",
    "    for key, val in baselines.items():\n",
    "        file_npz = experiments_path / key / audio.stem\n",
    "        \n",
    "        # if file exists, do nothing\n",
    "        if not file_npz.is_file():\n",
    "            start = time.perf_counter()\n",
    "            beats = val(x)\n",
    "            end = time.perf_counter()\n",
    "            \n",
    "            times[key][audio.stem] = end - start\n",
    "            \n",
    "            # is it better to create everything before looping?\n",
    "            utils.create_folder(file_npz.parent)\n",
    "\n",
    "            np.savez(file_npz, estimated=beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtzan\n",
    "for track_name in gtzan.track_ids:\n",
    "    x, _ = librosa.load(gtzan.track(track_name).audio_path, mono=True, sr=SR)\n",
    "    \n",
    "    for key, val in baselines.items():\n",
    "        file_npz = experiments_path / key / track_name\n",
    "                \n",
    "        # if file exists, do nothing\n",
    "        if not file_npz.is_file():\n",
    "            start = time.perf_counter()\n",
    "            beats = val(x)\n",
    "            end = time.perf_counter()\n",
    "\n",
    "            times[key][track_name] = end - start\n",
    "\n",
    "            # is it better to create everything before looping?\n",
    "            utils.create_folder(file_npz.parent)\n",
    "\n",
    "            np.savez(file_npz, estimated=beats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f19428",
   "metadata": {},
   "source": [
    "# output examples \n",
    "\n",
    "datasets:\n",
    "\n",
    "| track_id | dataset |\n",
    "| --- | --- |\n",
    "| track_1 | candombe | \n",
    "| track_2 | gtzan |\n",
    "\n",
    "\n",
    "beats:\n",
    "\n",
    "| track_id | dataset | reference | librosa_estimate | essentia_estimate | madmom_rnn_estimate | madmom_tcn_estimate |\n",
    "| --- | --- | --- | --- | --- | --- | --- | \n",
    "| track_1 | gtzan | np.array([...]) | np.array([...]) | np.array([...]) | np.array([...]) | np.array([...]) | \n",
    "\n",
    "performance:\n",
    "\n",
    "| track_id | dataset | librosa_time | essentia_time | madmom_rnn_time | madmom_tcn_time |\n",
    "| --- | --- | --- | --- | --- | --- | \n",
    "| track_1 | gtzan | 0.99 | 0.98 | 0.87 | 0.99 | 1.2 | \n",
    "\n",
    "\n",
    "metrics:\n",
    "\n",
    "| track_id | dataset | librosa_fmeasure | essentia_fmeasure | madmom_rnn_fmeasure | madmom_tcn_fmeasure |\n",
    "| --- | --- | --- | --- | --- | --- | \n",
    "| track_1 | gtzan | 0.99 | 0.98 | 0.87 | 0.99 | 1.2 | \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f783e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset dataframe\n",
    "datasets = {}\n",
    "\n",
    "for i in gtzan.track_ids:\n",
    "    datasets[i] = f\"gtzan.{i.split('.')[0]}\"\n",
    "\n",
    "for i in candombe_path.rglob(\"*.wav\"):\n",
    "    datasets[i.stem] = \"candombe\"\n",
    "\n",
    "dataset_df = pd.DataFrame.from_dict(datasets, orient=\"index\", columns=[\"dataset\"])\n",
    "dataset_df.index.name = \"track_id\"\n",
    "\n",
    "dataset_df.to_csv(experiments_path / \"experiment_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build time dataframe\n",
    "times_df = pd.DataFrame(times)\n",
    "times_df.index.name = \"track_id\"\n",
    "\n",
    "times_df.to_csv(experiments_path / \"processing_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e077d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_df = pd.read_csv(experiments_path / \"processing_time.csv\")\n",
    "times_df = times_df.set_index(\"track_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(experiments_path / \"experiment_data.csv\")\n",
    "dataset_df = dataset_df.set_index(\"track_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04549567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: document the default parameter for those algorithms\n",
    "# TODO: add more baselines? (e.g librosa with multi-channel?)\n",
    "# TODO: evaluate baselines against ground_truth value \n",
    "# TODO: parallelize experiments run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d072b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to group information in a dataframe or anything like this to \n",
    "# better analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1980f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're not worried about downbeat estimation, so let's first just save our beats\n",
    "\n",
    "# candombe\n",
    "csvfiles = candombe_path.rglob(\"*.csv\")\n",
    "reference = {}\n",
    "\n",
    "for file in csvfiles:\n",
    "    x_df = pd.read_csv(file, names=[\"timestamp\", \"beat\"])\n",
    "    \n",
    "    reference[file.stem] = {}\n",
    "    reference[file.stem][\"reference\"]  = x_df[\"timestamp\"].values\n",
    "    \n",
    "# gtzan\n",
    "for file in gtzan.track_ids:\n",
    "    reference[file] = {}\n",
    "    reference[file][\"reference\"] = gtzan.track(file).beats.times\n",
    "\n",
    "# gather estimations\n",
    "estimations = experiments_path.glob(\"*\")\n",
    "for folder in estimations:\n",
    "    print(f\"Reading files from /{folder.name}\")\n",
    "    for file in folder.glob(\"*.npz\"):\n",
    "        reference[file.stem][folder.name] = np.load(file)[\"estimated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efa4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_df = pd.DataFrame(reference).transpose()\n",
    "beat_df.index.name = \"track_id\"\n",
    "beat_df.to_csv(experiments_path / \"estimation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_df = pd.read_csv(experiments_path / \"estimation.csv\")\n",
    "beat_df = beat_df.set_index(\"track_id\")\n",
    "\n",
    "beat_df[\"reference\"] = beat_df[\"reference\"].to_numpy()\n",
    "beat_df[\"madmom_rnn\"] = beat_df[\"madmom_rnn\"].to_numpy()\n",
    "beat_df[\"madmom_tcn\"] = beat_df[\"madmom_tcn\"].to_numpy()\n",
    "beat_df[\"librosa\"] = beat_df[\"librosa\"].to_numpy()\n",
    "beat_df[\"essentia\"] = beat_df[\"essentia\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd800d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_df[\"madmom_rnn_metrics\"] = beat_df[[\"reference\", \"madmom_rnn\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"reference\"], x[\"madmom_rnn\"]), axis=1)\n",
    "beat_df[\"librosa_metrics\"] = beat_df[[\"reference\", \"librosa\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"reference\"], x[\"librosa\"]), axis=1)\n",
    "beat_df[\"madmom_tcn_metrics\"] = beat_df[[\"reference\", \"madmom_tcn\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"reference\"], x[\"madmom_tcn\"]), axis=1)\n",
    "beat_df[\"essentia_metrics\"] = beat_df[[\"reference\", \"essentia\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"reference\"], x[\"essentia\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b48e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(column_dict, index_column):\n",
    "    column_dict[\"track_id\"] = index_column\n",
    "    return column_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_df[\"madmom_rnn_metrics\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2505d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(beat_df[\"madmom_rnn_metrics\"].reset_index().apply(lambda x: tmp(x[\"madmom_rnn_metrics\"], x[\"track_id\"]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe743cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gambiarra nossa de cada dia\n",
    "madmom_rnn_metrics = pd.json_normalize(beat_df[\"madmom_rnn_metrics\"].reset_index().apply(lambda x: tmp(x[\"madmom_rnn_metrics\"], x[\"track_id\"]), axis=1)).set_index(\"track_id\")\n",
    "madmom_tcn_metrics = pd.json_normalize(beat_df[\"madmom_tcn_metrics\"].reset_index().apply(lambda x: tmp(x[\"madmom_tcn_metrics\"], x[\"track_id\"]), axis=1)).set_index(\"track_id\")\n",
    "librosa_metrics = pd.json_normalize(beat_df[\"librosa_metrics\"].reset_index().apply(lambda x: tmp(x[\"librosa_metrics\"], x[\"track_id\"]), axis=1)).set_index(\"track_id\")\n",
    "essentia_metrics = pd.json_normalize(beat_df[\"essentia_metrics\"].reset_index().apply(lambda x: tmp(x[\"essentia_metrics\"], x[\"track_id\"]), axis=1)).set_index(\"track_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9620d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "madmom_tcn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8304a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "madmom_tcn_metrics.join(dataset_df).groupby(\"dataset\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "madmom_rnn_metrics.join(dataset_df).groupby(\"dataset\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aae76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "essentia_metrics.join(dataset_df).groupby(\"dataset\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa_metrics.join(dataset_df).groupby(\"dataset\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e294e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f318ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import essentia\n",
    "import essentia.standard as es\n",
    "import librosa\n",
    "import librosa.display\n",
    "# IMPORTANT: since TCN is not available on pip version of madmom\n",
    "# you have to build the library from source\n",
    "import madmom\n",
    "import matplotlib.pyplot as plt\n",
    "import mirdata\n",
    "import mir_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import src.baseline as baseline\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path.cwd()\n",
    "\n",
    "experiments_path = base_path / \"results\" / \"baselines\"\n",
    "# output_path = base_path / \"experiments_results\" / \"beat_trackers_baseline\"\n",
    "candombe_path = base_path.parent / \"datasets\" / \"candombe\"\n",
    "sambaset_path = base_path.parent / \"datasets\" / \"sambaset-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b37225",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiments_path), print(candombe_path), print(sambaset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216d5a6",
   "metadata": {},
   "source": [
    "Important dataset information:\n",
    "* Candombe:\n",
    "    * sampling rate: 44100 Hz\n",
    "    * precision: 16-bit\n",
    "    * total audios: 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d137ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan = mirdata.initialize('gtzan_genre', version='mini')\n",
    "gtzan.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea638f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d0a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper dicts\n",
    "baselines = {\n",
    "    \"librosa\": baseline.librosa_beats,\n",
    "    \"madmom_rnn\": baseline.madmom_rnn_beats,\n",
    "    \"madmom_tcn\": baseline.madmom_tcn_beats,\n",
    "    \"essentia\": baseline.essentia_beats\n",
    "}\n",
    "\n",
    "times = {\n",
    "    \"librosa\": {},\n",
    "    \"madmom_rnn\": {},\n",
    "    \"madmom_tcn\": {},\n",
    "    \"essentia\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f6673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# candombe\n",
    "audiofiles = candombe_path.rglob(\"*.flac\")\n",
    "\n",
    "for audio in audiofiles:\n",
    "    x, _ = librosa.load(audio, mono=True, sr=SR)\n",
    "    \n",
    "    for key, val in baselines.items():\n",
    "        file_npz = experiments_path / key / (audio.stem + \".npz\")\n",
    "        \n",
    "        # if file exists, do nothing\n",
    "        if not file_npz.is_file():\n",
    "            start = time.perf_counter()\n",
    "            beats = val(x)\n",
    "            end = time.perf_counter()\n",
    "            \n",
    "            times[key][audio.stem] = end - start\n",
    "            \n",
    "            # is it better to create everything before looping?\n",
    "            utils.create_folder(file_npz.parent)\n",
    "\n",
    "            np.savez(file_npz, estimated=beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtzan\n",
    "for track_name in gtzan.track_ids:\n",
    "    x, _ = librosa.load(gtzan.track(track_name).audio_path, mono=True, sr=SR)\n",
    "    \n",
    "    for key, val in baselines.items():\n",
    "        file_npz = experiments_path / key / (track_name + \".npz\")\n",
    "                \n",
    "        # if file exists, do nothing\n",
    "        if not file_npz.is_file():\n",
    "            start = time.perf_counter()\n",
    "            beats = val(x)\n",
    "            end = time.perf_counter()\n",
    "\n",
    "            times[key][track_name] = end - start\n",
    "\n",
    "            # is it better to create everything before looping?\n",
    "            utils.create_folder(file_npz.parent)\n",
    "\n",
    "            np.savez(file_npz, estimated=beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09bbfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sambaset\n",
    "annotations_path = sambaset_path / \"annotations\" / \"beats\"\n",
    "audio_path = sambaset_path / \"audio\"\n",
    "\n",
    "for i in annotations_path.rglob(\"*.beats\"):\n",
    "    folder = i.stem.split(\".\")[0]\n",
    "    track_name = audio_path / folder / (i.stem + \".mp3\")\n",
    "    \n",
    "    x, _ = librosa.load(track_name, mono=True, sr=SR)\n",
    "    # skip first 30s\n",
    "    x = x[30*SR::]\n",
    "    for key, val in baselines.items():\n",
    "        file_npz = experiments_path / key / (track_name.stem + \".npz\")\n",
    "                \n",
    "        # if file exists, do nothing\n",
    "        if not file_npz.is_file():\n",
    "            start = time.perf_counter()\n",
    "            beats = val(x)\n",
    "            end = time.perf_counter()\n",
    "\n",
    "            times[key][track_name.stem] = end - start\n",
    "\n",
    "            # is it better to create everything before looping?\n",
    "            utils.create_folder(file_npz.parent)\n",
    "\n",
    "            np.savez(file_npz, estimated=beats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f19428",
   "metadata": {},
   "source": [
    "# output examples \n",
    "\n",
    "datasets:\n",
    "\n",
    "| track_id | dataset |\n",
    "| --- | --- |\n",
    "| track_1 | candombe | \n",
    "| track_2 | gtzan |\n",
    "\n",
    "\n",
    "beats:\n",
    "\n",
    "| track_id | dataset | reference | librosa_estimate | essentia_estimate | madmom_rnn_estimate | madmom_tcn_estimate |\n",
    "| --- | --- | --- | --- | --- | --- | --- | \n",
    "| track_1 | gtzan | np.array([...]) | np.array([...]) | np.array([...]) | np.array([...]) | np.array([...]) | \n",
    "\n",
    "performance:\n",
    "\n",
    "| track_id | dataset | librosa_time | essentia_time | madmom_rnn_time | madmom_tcn_time |\n",
    "| --- | --- | --- | --- | --- | --- | \n",
    "| track_1 | gtzan | 0.99 | 0.98 | 0.87 | 0.99 | 1.2 | \n",
    "\n",
    "\n",
    "metrics:\n",
    "\n",
    "| track_id | dataset | librosa_fmeasure | essentia_fmeasure | madmom_rnn_fmeasure | madmom_tcn_fmeasure |\n",
    "| --- | --- | --- | --- | --- | --- | \n",
    "| track_1 | gtzan | 0.99 | 0.98 | 0.87 | 0.99 | 1.2 | \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a51228",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_name.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae44786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build \"dataset\" dataframe\n",
    "datasets = {}\n",
    "\n",
    "for i in gtzan.track_ids:\n",
    "    # datasets[i] = f\"gtzan.{i.split('.')[0]}\"\n",
    "    datasets[i] = \"gtzan\"\n",
    "\n",
    "\n",
    "for i in candombe_path.rglob(\"*.flac\"):\n",
    "    datasets[i.stem] = \"candombe\"\n",
    "    \n",
    "for i in annotations_path.rglob(\"*.beats\"):\n",
    "    datasets[i.stem] = \"sambaset-mini\"\n",
    "\n",
    "dataset_df = pd.DataFrame.from_dict(datasets, orient=\"index\", columns=[\"dataset\"])\n",
    "dataset_df.index.name = \"track_id\"\n",
    "\n",
    "dataset_df.to_csv(experiments_path / \"experiment_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a8755",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.dataset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build time dataframe\n",
    "times_df = pd.DataFrame(times)\n",
    "times_df.index.name = \"track_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02442c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_df = times_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3546f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "times_df[\"track_id\"] = times_df[\"track_id\"].apply(lambda x: x.stem if type(x) == pathlib.PosixPath else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times_df.to_csv(experiments_path / \"processing_time.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e077d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_df = pd.read_csv(experiments_path / \"processing_time.csv\")\n",
    "times_df = times_df.set_index(\"track_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcc5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_times = times_df.join(dataset_df)\n",
    "genre_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78104374",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_times.boxplot(by=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db038c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = times_df.join(dataset_df).groupby(\"dataset\").boxplot(return_type=\"axes\")\n",
    "for i in ax.values:\n",
    "    i.set_ylabel(\"segundos\")\n",
    "    i.set_xlabel(\"método\")    \n",
    "\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f58a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving median time per dataset\n",
    "# times_df.join(dataset_df).groupby(\"dataset\").median().to_csv(experiments_path / \"median_time_per_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13905239",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(experiments_path / \"experiment_data.csv\")\n",
    "dataset_df = dataset_df.set_index(\"track_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04549567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: document the default parameter for those algorithms\n",
    "# TODO: add more baselines? (e.g librosa with multi-channel?)\n",
    "# TODO: evaluate baselines against ground_truth value \n",
    "# TODO: parallelize experiments run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d072b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to group information in a dataframe or anything like this to \n",
    "# better analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1980f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're not worried about downbeat estimation, so let's first just save our beats\n",
    "\n",
    "# candombe\n",
    "csvfiles = candombe_path.rglob(\"*.csv\")\n",
    "reference = {}\n",
    "\n",
    "for file in csvfiles:\n",
    "    x_df = pd.read_csv(file, names=[\"timestamp\", \"beat\"])\n",
    "    \n",
    "    reference[file.stem] = {}\n",
    "    reference[file.stem][\"reference\"]  = x_df[\"timestamp\"].values\n",
    "    \n",
    "# gtzan\n",
    "for file in gtzan.track_ids:\n",
    "    reference[file] = {}\n",
    "    reference[file][\"reference\"] = gtzan.track(file).beats.times\n",
    "\n",
    "# gather estimations\n",
    "estimations = experiments_path.glob(\"*\")\n",
    "for folder in estimations:\n",
    "    print(f\"Reading files from /{folder.name}\")\n",
    "    for file in folder.glob(\"*.npz\"):\n",
    "        reference[file.stem][folder.name] = np.load(file)[\"estimated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isso aqui fica horroroso. melhor salvar em um arquivo h5 ou como pickle. o csv fica muito ruim.\n",
    "beat_df = pd.DataFrame(reference).transpose()\n",
    "beat_df.index.name = \"track_id\"\n",
    "beat_df.to_csv(experiments_path / \"estimation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e11986",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_df = pd.read_csv(experiments_path / \"estimation.csv\")\n",
    "beat_df = beat_df.set_index(\"track_id\")\n",
    "\n",
    "beat_df[\"reference\"] = beat_df[\"reference\"].to_numpy()\n",
    "beat_df[\"madmom_rnn\"] = beat_df[\"madmom_rnn\"].to_numpy()\n",
    "beat_df[\"madmom_tcn\"] = beat_df[\"madmom_tcn\"].to_numpy()\n",
    "beat_df[\"librosa\"] = beat_df[\"librosa\"].to_numpy()\n",
    "beat_df[\"essentia\"] = beat_df[\"essentia\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_df[\"madmom_rnn_metrics\"] = beat_df[[\"reference\", \"madmom_rnn\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"reference\"], x[\"madmom_rnn\"]), axis=1)\n",
    "beat_df[\"librosa_metrics\"] = beat_df[[\"reference\", \"librosa\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"reference\"], x[\"librosa\"]), axis=1)\n",
    "beat_df[\"madmom_tcn_metrics\"] = beat_df[[\"reference\", \"madmom_tcn\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"reference\"], x[\"madmom_tcn\"]), axis=1)\n",
    "beat_df[\"essentia_metrics\"] = beat_df[[\"reference\", \"essentia\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"reference\"], x[\"essentia\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b48e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(column_dict, index_column):\n",
    "    column_dict[\"track_id\"] = index_column\n",
    "    return column_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab84c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_df[\"madmom_rnn_metrics\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a9d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(beat_df[\"madmom_rnn_metrics\"].reset_index().apply(lambda x: tmp(x[\"madmom_rnn_metrics\"], x[\"track_id\"]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe743cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gambiarra nossa de cada dia\n",
    "madmom_rnn_metrics = pd.json_normalize(beat_df[\"madmom_rnn_metrics\"].reset_index().apply(lambda x: tmp(x[\"madmom_rnn_metrics\"], x[\"track_id\"]), axis=1)).set_index(\"track_id\")\n",
    "madmom_tcn_metrics = pd.json_normalize(beat_df[\"madmom_tcn_metrics\"].reset_index().apply(lambda x: tmp(x[\"madmom_tcn_metrics\"], x[\"track_id\"]), axis=1)).set_index(\"track_id\")\n",
    "librosa_metrics = pd.json_normalize(beat_df[\"librosa_metrics\"].reset_index().apply(lambda x: tmp(x[\"librosa_metrics\"], x[\"track_id\"]), axis=1)).set_index(\"track_id\")\n",
    "essentia_metrics = pd.json_normalize(beat_df[\"essentia_metrics\"].reset_index().apply(lambda x: tmp(x[\"essentia_metrics\"], x[\"track_id\"]), axis=1)).set_index(\"track_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875159a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving metrics\n",
    "madmom_tcn_metrics.to_csv(experiments_path / \"madmom_tcn_metrics.csv\")\n",
    "madmom_rnn_metrics.to_csv(experiments_path / \"madmom_rnn_metrics.csv\")\n",
    "librosa_metrics.to_csv(experiments_path / \"librosa_metrics.csv\")\n",
    "essentia_metrics.to_csv(experiments_path / \"essentia_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc71b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving median metric per dataset\n",
    "# madmom_tcn_metrics.join(dataset_df).groupby(\"dataset\").median().to_csv(experiments_path / \"madmom_tcn_metrics_per_dataset.csv\")\n",
    "# madmom_rnn_metrics.join(dataset_df).groupby(\"dataset\").median().to_csv(experiments_path / \"madmom_rnn_metrics_per_dataset.csv\")\n",
    "# librosa_metrics.join(dataset_df).groupby(\"dataset\").median().to_csv(experiments_path / \"librosa_metrics_per_dataset.csv\")\n",
    "# essentia_metrics.join(dataset_df).groupby(\"dataset\").median().to_csv(experiments_path / \"essentia_metrics_per_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7812ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "madmom_tcn_metrics.join(dataset_df).groupby(\"dataset\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "madmom_rnn_metrics.join(dataset_df).groupby(\"dataset\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "essentia_metrics.join(dataset_df).groupby(\"dataset\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e95ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa_metrics.join(dataset_df).groupby(\"dataset\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e294e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f318ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import essentia\n",
    "import essentia.standard as es\n",
    "import librosa\n",
    "import librosa.display\n",
    "# IMPORTANT: since TCN is not available on pip version of madmom\n",
    "# you have to build the library from source\n",
    "import madmom\n",
    "import matplotlib.pyplot as plt\n",
    "import mir_eval\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path.cwd()\n",
    "\n",
    "experiments_path = base_path / \"results\" / \"baselines\"\n",
    "# output_path = base_path / \"experiments_results\" / \"beat_trackers_baseline\"\n",
    "dataset_path = base_path.parent.parent / \"datasets\" / \"candombe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216d5a6",
   "metadata": {},
   "source": [
    "Important dataset information:\n",
    "* Candombe:\n",
    "    * sampling rate: 44100 Hz\n",
    "    * precision: 16-bit\n",
    "    * total audios: 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea638f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 44100\n",
    "TOTAL_AUDIOS = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c66d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def librosa_beats(audio):\n",
    "    bpm, beats = librosa.beat.beat_track(x, sr=SR, units=\"time\")\n",
    "    return beats\n",
    "\n",
    "# TODO: fix this one\n",
    "def librosa_beats_with_onset_agg(audio):\n",
    "    onset_subbands = librosa.onset.onset_strength_multi(y=audio, sr=SR, channels=[0, 32, 64, 96, 128])\n",
    "    bpm, beats = librosa.beat.beat_track(onset_envelope=onset_subbands, sr=SR)\n",
    "    return beats\n",
    "\n",
    "def essentia_beats(audio):\n",
    "    beats, confidence = es.BeatTrackerMultiFeature()(x)\n",
    "    return beats\n",
    "\n",
    "#refence for implementation https://github.com/CPJKU/madmom/issues/403\n",
    "def madmom_rnn_beats(audio):\n",
    "    beat_processor = madmom.features.beats.RNNBeatProcessor()\n",
    "    beat_decoder = madmom.features.beats.DBNBeatTrackingProcessor(beats_per_bar=[4], fps=100)\n",
    "    beats = beat_decoder(beat_processor(audio))\n",
    "    return beats\n",
    "\n",
    "def madmom_tcn_beats(audio):\n",
    "    beat_processor = madmom.features.beats.TCNBeatProcessor()\n",
    "    beat_decoder = madmom.features.beats.DBNBeatTrackingProcessor(beats_per_bar=[4], fps=100)\n",
    "    beats = beat_decoder(beat_processor(audio))\n",
    "    return beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d0a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = {\n",
    "    \"librosa\": {\"function\": librosa_beats, \"time\": np.zeros(TOTAL_AUDIOS)},\n",
    "    \"madmom_rnn\": {\"function\": madmom_rnn_beats, \"time\": np.zeros(TOTAL_AUDIOS)},\n",
    "    \"madmom_tcn\": {\"function\": madmom_tcn_beats, \"time\": np.zeros(TOTAL_AUDIOS)},\n",
    "    \"essentia\": {\"function\": essentia_beats, \"time\": np.zeros(TOTAL_AUDIOS)}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f6673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audiofiles = dataset_path.rglob(\"*.wav\")\n",
    "\n",
    "idx = 0\n",
    "for audio in audiofiles:\n",
    "    x, _ = librosa.load(audio, mono=True, sr=SR)\n",
    "    \n",
    "    for key, val in baselines.items():\n",
    "        file_npz = experiments_path / key / audio.stem\n",
    "        \n",
    "        # if file exists, do nothing\n",
    "        if not file_npz.is_file():\n",
    "            start = time.perf_counter()\n",
    "            beats = val[\"function\"](x)\n",
    "            end = time.perf_counter()\n",
    "            val[\"time\"][idx] = end - start\n",
    "\n",
    "            if not file_npz.parent.is_dir():\n",
    "                print(f\"Creating folder for {file_npz.parent}\")\n",
    "                file_npz.parent.mkdir(parents=True)\n",
    "\n",
    "            np.savez(file_npz, estimated=beats)    \n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b64191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in baselines.items():\n",
    "    print(f\"{key} time metrics\")\n",
    "    print(f\"\\tavg time {np.mean(val['time']):0.4f} seconds\")\n",
    "    print(f\"\\tmedian time {np.median(val['time']):0.4f} seconds\")\n",
    "    print(f\"\\tmax time {np.max(val['time']):0.4f} seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04549567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: document the default parameter for those algorithms\n",
    "# TODO: add more baselines? (e.g librosa with multi-channel?)\n",
    "# TODO: evaluate baselines against ground_truth value \n",
    "# TODO: parallelize experiments run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1032f29",
   "metadata": {},
   "source": [
    "# baseline evaluation\n",
    "* main metrics for each method separatedly\n",
    "* metrics compared between each other (<- ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d072b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to group information in a dataframe or anything like this to \n",
    "# better analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aeed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're not worried about downbeat estimation, so let's first just save our beats\n",
    "csvfiles = dataset_path.rglob(\"*.csv\")\n",
    "reference = {}\n",
    "\n",
    "for file in csvfiles:\n",
    "    x_df = pd.read_csv(csv, names=[\"timestamp\", \"beat\"])\n",
    "    \n",
    "    reference[file.stem] = {}\n",
    "    reference[file.stem][\"baseline\"]  = x_df[\"timestamp\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimations = experiments_path.glob(\"*\")\n",
    "for folder in estimations:\n",
    "    print(f\"Reading files from /{folder.name}\")\n",
    "    for file in folder.glob(\"*.npz\"):\n",
    "        reference[file.stem][folder.name] = np.load(file)[\"estimated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb445025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reference).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"madmom_rnn_metrics\"] = df[[\"baseline\", \"madmom_rnn\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"baseline\"], x[\"madmom_rnn\"]), axis=1)\n",
    "df[\"librosa_metrics\"] = df[[\"baseline\", \"librosa\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"baseline\"], x[\"librosa\"]), axis=1)\n",
    "df[\"madmom_tcn_metrics\"] = df[[\"baseline\", \"madmom_tcn\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"baseline\"], x[\"madmom_tcn\"]), axis=1)\n",
    "df[\"essentia_metrics\"] = df[[\"baseline\", \"essentia\"]].apply(lambda x: mir_eval.beat.evaluate(x[\"baseline\"], x[\"essentia\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac43742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[[\"madmom_rnn_metrics\", \"librosa_metrics\", \"madmom_tcn_metrics\", \"essentia_metrics\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4968be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.json_normalize(df[[\"madmom_rnn_metrics\", \"librosa_metrics\", \"madmom_tcn_metrics\", \"essentia_metrics\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(df[\"madmom_tcn_metrics\"]).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(df[\"madmom_rnn_metrics\"]).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c88a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(df[\"librosa_metrics\"]).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e23970",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(df[\"essentia_metrics\"]).median()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
